+++
date = "2024-01-16"
+++
Our new paper [A Data-Driven Measure of Relative Uncertainty for Misclassification Detection](https://openreview.net/forum?id=ruGY8v10mK&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2024%2FConference%2FAuthors%23your-submissions)) has been accepted to appear at [ICLR 2024](https://iclr.cc/). In this paper we proposed a data-driven method, powered by a statistical diversity and dissimilarity metric, to detect incorrect classification at test time by assessing the uncertainty of a given model.

A huge shout-out to my great colleagues [Eduardo](https://edadaltocg.github.io/), [Georg](https://scholar.google.at/citations?user=5lv1oKAAAAAJ&hl=en), and [Pablo](https://sites.google.com/mila.quebec/pablo-piantanida/home) for their fantastic work!

A preliminary version of [this paper](https://openreview.net/forum?id=7iibkkg0WI&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DNeurIPS.cc%2F2023%2FWorkshop%2FM3L%2FAuthors%23your-submissions)) has appeared at the [NeurIPS 2023 Workshop on Mathematics of Modern Machine Learning](https://sites.google.com/view/m3l-2023).
