+++
date = "2024-05-31"
+++
Check out our new preprint [Low-rank fine-tuning for LLMs: A fairness perspective
](https://arxiv.org/pdf/2405.18572)! In this paper we analyzed the effects of Low Rank fine-tuning (LoRA) on the fairness and bias of Large Language Models (LLMs).

A huge shout-out to my great colleagues [Saswat](https://saswatdas.com/) and [Ferdinando](https://nandofioretto.github.io/) for their fantastic work!
